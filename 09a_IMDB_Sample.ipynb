{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09a_IMDB_Sample.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oo_JtWcaJPL",
        "colab_type": "text"
      },
      "source": [
        "# Natural Langauge Processing\n",
        "\n",
        "The `09` notebooks will cover a variety of NLP topics. This first notebook will cover how to use text in a CSV document with the `IMDB_SAMPLE` dataset, along with training a model. First let's install what we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeoa2LeMZ9jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install torch torchvision feather-format kornia pyarrow Pillow wandb --upgrade \n",
        "!pip install git+https://github.com/fastai/fastai_dev  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47cU9_lPbEk6",
        "colab_type": "text"
      },
      "source": [
        "# Data Preperation\n",
        "\n",
        "With fastai 2.0, the text pipeline has been completely reworked. Now we can pre-tokenize our data beforehand to allow for a much faster time getting our data ready.\n",
        "\n",
        "Let's grab the imports we will be using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-1IJJP_adOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.basics import *\n",
        "from fastai2.text.all import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUMbDOBybuuM",
        "colab_type": "text"
      },
      "source": [
        "Let's grab our data and tokenize it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grBTAGtfbskv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = untar_data(URLs.IMDB_SAMPLE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArfqrT-7cETx",
        "colab_type": "text"
      },
      "source": [
        "We now have a variety of `tokenize_` functions designed for tokenizing from various sources. We have a `tokenize_folder`, `tokenize_csv`, and `tokenize_df` function. We will use `tokenize_df` here. \n",
        "\n",
        "We need to dictate which column in our `csv` contains our text. In our case it is the `text` column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmFeP6aolTll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(path/'texts.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaYA4k6ebzHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_tok, count = tokenize_df(df, text_cols='text')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVR2TGuCs3-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "157823d1-838e-4029-eb5c-00664099efb6"
      },
      "source": [
        "df_tok.head()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>is_valid</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>negative</td>\n",
              "      <td>False</td>\n",
              "      <td>[xxbos, xxmaj, un, -, bleeping, -, believable, !, xxmaj, meg, xxmaj, ryan, does, n't, even, look, her, usual, pert, lovable, self, in, this, ,, which, normally, makes, me, forgive, her, shallow, ticky, acting, schtick, ., xxmaj, hard, to, believe, she, was, the, producer, on, this, dog, ., xxmaj, plus, xxmaj, kevin, xxmaj, kline, :, what, kind, of, suicide, trip, has, his, career, been, on, ?, xxmaj, whoosh, …, xxmaj, banzai, xxrep, 3, !, xxmaj, finally, this, was, directed, by, the, guy, who, did, xxmaj, big, xxmaj, chill, ?, xxmaj, must, be, a, replay, of, xxmaj, jonestown, -, hollywood,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>False</td>\n",
              "      <td>[xxbos, xxmaj, this, is, a, extremely, well, -, made, film, ., xxmaj, the, acting, ,, script, and, camera, -, work, are, all, first, -, rate, ., xxmaj, the, music, is, good, ,, too, ,, though, it, is, mostly, early, in, the, film, ,, when, things, are, still, relatively, cheery, ., xxmaj, there, are, no, really, superstars, in, the, cast, ,, though, several, faces, will, be, familiar, ., xxmaj, the, entire, cast, does, an, excellent, job, with, the, script, ., \\n\\n, xxmaj, but, it, is, hard, to, watch, ,, because, there, is, no, good, end, to, a, situation, like, the, one, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>negative</td>\n",
              "      <td>False</td>\n",
              "      <td>[xxbos, xxmaj, every, once, in, a, long, while, a, movie, will, come, along, that, will, be, so, awful, that, i, feel, compelled, to, warn, people, ., xxmaj, if, i, labor, all, my, days, and, i, can, save, but, one, soul, from, watching, this, movie, ,, how, great, will, be, my, joy, ., \\n\\n, xxmaj, where, to, begin, my, discussion, of, pain, ., xxmaj, for, starters, ,, there, was, a, musical, montage, every, five, minutes, ., xxmaj, there, was, no, character, development, ., xxmaj, every, character, was, a, stereotype, ., xxmaj, we, had, swearing, guy, ,, fat, guy, who, eats, donuts, ...]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>positive</td>\n",
              "      <td>False</td>\n",
              "      <td>[xxbos, xxmaj, name, just, says, it, all, ., i, watched, this, movie, with, my, dad, when, it, came, out, and, having, served, in, xxmaj, korea, he, had, great, admiration, for, the, man, ., xxmaj, the, disappointing, thing, about, this, film, is, that, it, only, concentrate, on, a, short, period, of, the, man, 's, life, -, interestingly, enough, the, man, 's, entire, life, would, have, made, such, an, epic, bio, -, pic, that, it, is, staggering, to, imagine, the, cost, for, production, ., \\n\\n, xxmaj, some, posters, elude, to, the, flawed, characteristics, about, the, man, ,, which, are, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>False</td>\n",
              "      <td>[xxbos, xxmaj, this, movie, succeeds, at, being, one, of, the, most, unique, movies, you, 've, seen, ., xxmaj, however, this, comes, from, the, fact, that, you, ca, n't, make, heads, or, tails, of, this, mess, ., xxmaj, it, almost, seems, as, a, series, of, challenges, set, up, to, determine, whether, or, not, you, are, willing, to, walk, out, of, the, movie, and, give, up, the, money, you, just, paid, ., xxmaj, if, you, do, n't, want, to, feel, slighted, you, 'll, sit, through, this, horrible, film, and, develop, a, real, sense, of, pity, for, the, actors, involved, ,, they, 've, ...]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text\n",
              "0  negative  ...  [xxbos, xxmaj, un, -, bleeping, -, believable, !, xxmaj, meg, xxmaj, ryan, does, n't, even, look, her, usual, pert, lovable, self, in, this, ,, which, normally, makes, me, forgive, her, shallow, ticky, acting, schtick, ., xxmaj, hard, to, believe, she, was, the, producer, on, this, dog, ., xxmaj, plus, xxmaj, kevin, xxmaj, kline, :, what, kind, of, suicide, trip, has, his, career, been, on, ?, xxmaj, whoosh, …, xxmaj, banzai, xxrep, 3, !, xxmaj, finally, this, was, directed, by, the, guy, who, did, xxmaj, big, xxmaj, chill, ?, xxmaj, must, be, a, replay, of, xxmaj, jonestown, -, hollywood,...\n",
              "1  positive  ...                 [xxbos, xxmaj, this, is, a, extremely, well, -, made, film, ., xxmaj, the, acting, ,, script, and, camera, -, work, are, all, first, -, rate, ., xxmaj, the, music, is, good, ,, too, ,, though, it, is, mostly, early, in, the, film, ,, when, things, are, still, relatively, cheery, ., xxmaj, there, are, no, really, superstars, in, the, cast, ,, though, several, faces, will, be, familiar, ., xxmaj, the, entire, cast, does, an, excellent, job, with, the, script, ., \\n\\n, xxmaj, but, it, is, hard, to, watch, ,, because, there, is, no, good, end, to, a, situation, like, the, one, ...]\n",
              "2  negative  ...     [xxbos, xxmaj, every, once, in, a, long, while, a, movie, will, come, along, that, will, be, so, awful, that, i, feel, compelled, to, warn, people, ., xxmaj, if, i, labor, all, my, days, and, i, can, save, but, one, soul, from, watching, this, movie, ,, how, great, will, be, my, joy, ., \\n\\n, xxmaj, where, to, begin, my, discussion, of, pain, ., xxmaj, for, starters, ,, there, was, a, musical, montage, every, five, minutes, ., xxmaj, there, was, no, character, development, ., xxmaj, every, character, was, a, stereotype, ., xxmaj, we, had, swearing, guy, ,, fat, guy, who, eats, donuts, ...]\n",
              "3  positive  ...  [xxbos, xxmaj, name, just, says, it, all, ., i, watched, this, movie, with, my, dad, when, it, came, out, and, having, served, in, xxmaj, korea, he, had, great, admiration, for, the, man, ., xxmaj, the, disappointing, thing, about, this, film, is, that, it, only, concentrate, on, a, short, period, of, the, man, 's, life, -, interestingly, enough, the, man, 's, entire, life, would, have, made, such, an, epic, bio, -, pic, that, it, is, staggering, to, imagine, the, cost, for, production, ., \\n\\n, xxmaj, some, posters, elude, to, the, flawed, characteristics, about, the, man, ,, which, are, ...\n",
              "4  negative  ...         [xxbos, xxmaj, this, movie, succeeds, at, being, one, of, the, most, unique, movies, you, 've, seen, ., xxmaj, however, this, comes, from, the, fact, that, you, ca, n't, make, heads, or, tails, of, this, mess, ., xxmaj, it, almost, seems, as, a, series, of, challenges, set, up, to, determine, whether, or, not, you, are, willing, to, walk, out, of, the, movie, and, give, up, the, money, you, just, paid, ., xxmaj, if, you, do, n't, want, to, feel, slighted, you, 'll, sit, through, this, horrible, film, and, develop, a, real, sense, of, pity, for, the, actors, involved, ,, they, 've, ...]\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuzBXpmPldRK",
        "colab_type": "text"
      },
      "source": [
        "The above will return a tokenized `DataFrame` along with a `Counter`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsE7Gb1-ddnx",
        "colab_type": "text"
      },
      "source": [
        "count now contains a `Counter` that has all of our words (including tokens) in it, along with how often they show up. To find our most common words, we can pass in `n` to `.most_common`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyA0UMhrdPCs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "211c5310-d7b6-47c3-d4ac-0bb1299b26a2"
      },
      "source": [
        "count.most_common(n=5)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('xxmaj', 24930), ('the', 14467), (',', 11834), ('.', 11735), ('and', 6949)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ1Qn0rWd4wC",
        "colab_type": "text"
      },
      "source": [
        "From here we can then call `make_vocab` and pass in this `count` to generate our vocabulary! We can also pass in a minimum frequency and a maximum vocabulary too. By default, this is set to 3 and 60,000 respectively"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1sTQFind-pu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = make_vocab(count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3jmjXUzeaFJ",
        "colab_type": "text"
      },
      "source": [
        "vocab is now an array of our vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ChrrhZWeKrK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "404a4f88-6575-46d6-fe4a-c3c13b4bddfc"
      },
      "source": [
        "vocab[100]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'get'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQUPu9pLeiA6",
        "colab_type": "text"
      },
      "source": [
        "Now we can generate our splits and our `DataBunch` using the `DataBlock` API. We will use just one block for our language model, a `TextBlock` where we pass in our `vocab` and specify it is a language model (`is_lm`), how we want to grab our data (`ColReader`), and how we want to split our data (Randomly with 10% in validation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFGpnjmLhD1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imbd_lm = DataBlock(blocks=(TextBlock(vocab, is_lm=True), ),\n",
        "                    get_x=ColReader('text'),\n",
        "                    splitter=RandomSplitter(0.1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qS2B56YDijh_",
        "colab_type": "text"
      },
      "source": [
        "Now we can databunch it, passing in our tokenized `DataFrame`, a batch size, and a sequence length. A sequence length is how many words back we will be keeping during our batch. We will use the last 72 words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DaMtqVEiiyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbunch_lm = imdb_lm.databunch(df_tok, bs=64, seq_len=72)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcYMah3-jIhZ",
        "colab_type": "text"
      },
      "source": [
        "Now let's take a look at it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIt76O17jH7I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "outputId": "9c7dc386-00b1-4037-dcf3-ddcf20cfacdb"
      },
      "source": [
        "dbunch_lm.show_batch(max_n=6)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos i thoroughly enjoyed this film for its humor and pathos . i especially like the way the characters welcomed xxmaj gina 's various suitors . xxmaj with friends ( and family ) like these anyone would feel xxunk and loved . i found the writing witty and natural and the actors made the material come alive . xxbos xxmaj not only does the film 's author , xxmaj steven xxmaj greenstreet</td>\n",
              "      <td>i thoroughly enjoyed this film for its humor and pathos . i especially like the way the characters welcomed xxmaj gina 's various suitors . xxmaj with friends ( and family ) like these anyone would feel xxunk and loved . i found the writing witty and natural and the actors made the material come alive . xxbos xxmaj not only does the film 's author , xxmaj steven xxmaj greenstreet ,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>that time did n't take it any more seriously than modern viewers could . \\n\\n xxmaj this movie is exactly what the xxunk tend to think of as a ' typical ' silent movie , with it 's archaic moral structure , wooden acting and bad direction . demille shows that he could be a terrible director , with no sense of pacing , camera xxunk , or skill in handling either</td>\n",
              "      <td>time did n't take it any more seriously than modern viewers could . \\n\\n xxmaj this movie is exactly what the xxunk tend to think of as a ' typical ' silent movie , with it 's archaic moral structure , wooden acting and bad direction . demille shows that he could be a terrible director , with no sense of pacing , camera xxunk , or skill in handling either script</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxmaj grey xxmaj gardens to anyone who enjoys documentaries . xxmaj perhaps someday someone will come along and do a documentary about this documentary - bringing in the rich xxunk ( and xxunk ) of the xxmaj beales and the whole xxunk of xxmaj xxunk society in the 1970 's . xxbos i was looking forward to xxmaj kathryn xxmaj xxunk 's movie with great anticipation after the endless hype and 6</td>\n",
              "      <td>grey xxmaj gardens to anyone who enjoys documentaries . xxmaj perhaps someday someone will come along and do a documentary about this documentary - bringing in the rich xxunk ( and xxunk ) of the xxmaj beales and the whole xxunk of xxmaj xxunk society in the 1970 's . xxbos i was looking forward to xxmaj kathryn xxmaj xxunk 's movie with great anticipation after the endless hype and 6 xxmaj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>movie , nothing much except for dialogue between two characters for an hour and a half , it 's likely to bore all but true fans of the xxmaj beatles ; but it 's a fantastic piece of writing and storytelling , and is both informative and touching . xxmaj for those interested in these two musical giants , very quickly you 'll get over the shock of how different the actors</td>\n",
              "      <td>, nothing much except for dialogue between two characters for an hour and a half , it 's likely to bore all but true fans of the xxmaj beatles ; but it 's a fantastic piece of writing and storytelling , and is both informative and touching . xxmaj for those interested in these two musical giants , very quickly you 'll get over the shock of how different the actors look</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>and the undead , with our heroes going into the reactor 's lower levels to take out the flesh eating zombies and xxunk the hole forever ! xxmaj pretty cheesy , but i think it was meant to be . xxmaj still , it moves very fast , has xxunk of gruesome effects and really tries to have some style . xxmaj the acting is uneven , but a few good performances</td>\n",
              "      <td>the undead , with our heroes going into the reactor 's lower levels to take out the flesh eating zombies and xxunk the hole forever ! xxmaj pretty cheesy , but i think it was meant to be . xxmaj still , it moves very fast , has xxunk of gruesome effects and really tries to have some style . xxmaj the acting is uneven , but a few good performances shine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>but at least violence and killing are ( finally ) seen to have an emotional and psychological impact on those who xxunk and those who merely witness such acts . xxmaj the whole thing is xxunk of a previous age and previous movies but it xxunk away the old and xxunk with a modern tale of redemption xxunk the tommy - gun xxunk and xxunk xxunk . xxmaj it can feel a</td>\n",
              "      <td>at least violence and killing are ( finally ) seen to have an emotional and psychological impact on those who xxunk and those who merely witness such acts . xxmaj the whole thing is xxunk of a previous age and previous movies but it xxunk away the old and xxunk with a modern tale of redemption xxunk the tommy - gun xxunk and xxunk xxunk . xxmaj it can feel a little</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3P2-rU8jug-",
        "colab_type": "text"
      },
      "source": [
        "Great! Now let's begin training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTspjUoujv2G",
        "colab_type": "text"
      },
      "source": [
        "## Training the Language Model\n",
        "\n",
        "We have a familiary `language_model_learner` here, in which we can pass in our `DataBunch`, our architecture (`AWD_LSTM`), our vocabulary, optimizer, and our metrics. We will use accuracy and Perplexity. To read more on perplexity see [here](https://en.wikipedia.org/wiki/Perplexity)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xznl-UKdjb51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_func = partial(Adam, wd=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4SmqSeKkQWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = language_model_learner(dbunch_lm, AWD_LSTM, vocab, opt_func=opt_func, metrics=[accuracy, Perplexity()], path=path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV6UY1zEnQzw",
        "colab_type": "text"
      },
      "source": [
        "We can then also use Mixed Precision to speed up training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNr2VRggkrCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = learn.to_fp16(clip=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQr2fZZ7nVpS",
        "colab_type": "text"
      },
      "source": [
        "Now let's fit! Since we used a pre-trained WikiText103 model, we need to fit for an epoch and then unfreeze the rest of our layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrhWm04onU52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "ec771ec1-55e3-4aa0-aced-b6191cb8a87f"
      },
      "source": [
        "learn.fit_one_cycle(1, 2e-3, moms=(0.8,0.7,0.8))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.693562</td>\n",
              "      <td>4.143623</td>\n",
              "      <td>0.271171</td>\n",
              "      <td>63.030762</td>\n",
              "      <td>00:29</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFcWSCVkntNe",
        "colab_type": "text"
      },
      "source": [
        "Great! Now let's train the rest. Ideally you'd want to run for 10 epochs or so, but since this is such a small sample, we will fit once as we overfit quite quickly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlrw8W-knjuN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "e741b7dd-51ba-4aca-b14c-4027488ef571"
      },
      "source": [
        "learn.unfreeze()\n",
        "learn.fit_one_cycle(1, 2e-3, moms=(0.8,0.7,0.8))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>perplexity</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.407096</td>\n",
              "      <td>3.987406</td>\n",
              "      <td>0.285446</td>\n",
              "      <td>53.914879</td>\n",
              "      <td>00:37</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RngQBDxypYZz",
        "colab_type": "text"
      },
      "source": [
        "Now we have a language model. Let's save the encoder away and move onto our classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AQes87woT26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn.save_encoder('finetuned')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AtrBpG_peoG",
        "colab_type": "text"
      },
      "source": [
        "# Classification\n",
        "\n",
        "Now let's move onto our classifier. The `DataBlock` for this will look *very* similar. We just need to specify two things. We want our `y`'s to be `CategoryBlocks` (categories), and we need to say how we want to get our x and y's. We can do it one of two ways, we can dictate via an `attrgetter` and  `ColumnReader` which column contains our text, or we can create a function. As our data is ordered, we also need to specify our `DataLoader`'s type as a `SortedDL`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9SxvwL9pdss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb_clas = DataBlock(blocks=(TextBlock(vocab), CategoryBlock),\n",
        "                      get_x=attrgetter('text'),\n",
        "                      get_y=ColReader('label'),\n",
        "                      splitter=RandomSplitter(),\n",
        "                      dl_type=SortedDL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QU5tv-FLqNQt",
        "colab_type": "text"
      },
      "source": [
        "We can then `DataBunch` it the exact same, passing in our tokenized `DataFrame`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqDjDf-rqwp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbunch = imdb_clas.databunch(df_tok, bs=64, seq_len=72)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9HslsdIqz9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "d4854095-e67a-47b7-dd57-0344a909e607"
      },
      "source": [
        "dbunch.show_batch(max_n=2)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos good movie , good music , good background and an acceptable plot . but the main point again as his movies tend to be , the man is the best actor in xxunk and can turn xxunk into gold . xxunk xxunk . this may be his second best performance after xxunk ( others may disagree ) . although other movies are not far behind . one man that will never ever disappoint you . \\n\\n good movie although i think xxunk was a luxury this movie could have done without . you can see in his movies , others try very hard to reach his heights and act out of their skins . but this man is really something xxunk . \\n\\n the movie is cool , the music and direction is excellent plot a bit thin but the screen play and dialog again very good . a must watch .</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos xxmaj un - xxunk - believable ! xxmaj meg xxmaj ryan does n't even look her usual xxunk lovable self in this , which normally makes me forgive her shallow xxunk acting xxunk . xxmaj hard to believe she was the producer on this dog . xxmaj plus xxmaj kevin xxmaj kline : what kind of suicide trip has his career been on ? xxmaj xxunk … xxmaj xxunk xxrep 3 ! xxmaj finally this was directed by the guy who did xxmaj big xxmaj xxunk ? xxmaj must be a replay of xxmaj jonestown - hollywood style . w xxrep 3 o xxrep 3 f !</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAnuTLjZuDvI",
        "colab_type": "text"
      },
      "source": [
        "The other method is to use a custom `get_items` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBVvJz94q18T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _imdb_items(x): return (\n",
        "    x['text'], x['label'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJDNZeojuUX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imdb_clas = DataBlock(blocks=(TextBlock(vocab), CategoryBlock),\n",
        "                      get_items = _imdb_items,\n",
        "                      splitter=RandomSplitter(),\n",
        "                      dl_type=SortedDL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAK0hk5KuY3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dbunch = imdb_clas.databunch(df_tok, bs=64, seq_len=72)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_mEyJNzucIp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "33024182-2e84-41be-a0e2-f17e9eca0839"
      },
      "source": [
        "dbunch.show_batch(max_n=4)"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>xxbos xxmaj raising xxmaj victor xxmaj vargas : a xxmaj review \\n\\n xxmaj you know , xxmaj raising xxmaj victor xxmaj vargas is like sticking your hands into a big , xxunk bowl of xxunk . xxmaj it 's warm and gooey , but you 're not sure if it feels right . xxmaj try as i might , no matter how warm and gooey xxmaj raising xxmaj victor xxmaj vargas became i was always aware that something did n't quite feel right . xxmaj victor xxmaj vargas suffers from a certain xxunk on the director 's part . xxmaj apparently , the director thought that the ethnic backdrop of a xxmaj latino family on the lower east side , and an xxunk storyline would make the film critic proof . xxmaj he was right , but it did n't fool me . xxmaj raising xxmaj victor xxmaj vargas is the story about a xxunk - year old boy called , you guessed it , xxmaj victor xxmaj vargas ( victor xxmaj xxunk ) who lives his teenage years chasing more xxunk than the xxmaj rolling xxmaj xxunk could do in all the years they 've xxunk . xxmaj the movie starts off in ` ugly xxmaj fat ' xxmaj donna 's bedroom where xxmaj victor is sure to seduce her , but a cry from outside xxunk his plans when his best - friend xxmaj harold ( kevin xxmaj xxunk ) comes - a - looking for him . xxmaj caught in the attempt by xxmaj harold and his sister , xxmaj victor xxmaj vargas runs off for xxunk control . xxmaj yet even with the embarrassing implication that he 's been xxunk the xxunk girl in the neighborhood , nothing xxunk young xxmaj victor from going off on the hunt for more fresh meat . xxmaj on a hot , xxmaj new xxmaj york xxmaj city day they make way to the local public swimming pool where xxmaj victor 's eyes catch a glimpse of the lovely young xxunk xxmaj judy ( judy xxmaj xxunk ) , who 's not just pretty , but a strong and independent too . xxmaj the relationship that develops between xxmaj victor and xxmaj judy becomes the focus of the film . xxmaj the story also focuses on xxmaj victor 's family that is comprised of his grandmother or xxunk ( xxunk xxmaj guzman ) , his brother xxmaj nino ( also played by real life brother to xxmaj victor , xxmaj xxunk xxmaj xxunk ) and his sister xxmaj vicky ( xxunk xxmaj xxunk ) . xxmaj the action follows xxmaj victor between scenes with xxmaj judy and scenes with his family . xxmaj victor tries to xxunk with being an oversexed pimp - daddy , his feelings for xxmaj judy and his grandmother 's conservative xxmaj catholic upbringing . \\n\\n xxmaj the problems that xxunk from xxmaj raising xxmaj victor xxmaj vargas are a few , but glaring errors . xxmaj throughout the film you get to know certain characters like xxmaj vicky , xxmaj nino , xxmaj xxunk , xxmaj judy and even xxmaj judy 's best friend xxmaj xxunk . xxmaj the problem is , we know nothing of xxmaj victor xxmaj vargas except that he is the biggest gigolo in the neighborhood . xxmaj we know that he knows how to lick his lips , and xxunk his xxunk , and carry himself for the sake of xxunk girls into the xxunk , but that 's all . xxmaj we know that xxmaj nino plays piano , and quiet well , you could see it by the awards on the family piano . xxmaj we know his sister xxmaj xxunk , is a gossip - loving girl with an xxunk interest in watching xxup tv . xxmaj we know that xxunk is a hard - working traditional xxmaj xxunk woman who 's trying to raise her kids with xxunk in a world of excess corruption . xxmaj yet where is the titular character , xxmaj victor xxmaj vargas ? xxmaj he 's in this movie somewhere , but we only know what the movie tells us . xxmaj this is by far the film 's biggest flaw . xxmaj victor xxmaj vargas is n't so much a character but a xxunk - xxunk ball , xxunk between scenes with xxmaj judy and his xxmaj grandmother , but we never get to know who xxmaj victor xxmaj vargas really is . xxmaj this is important because as xxmaj i 've mentioned the only thing we know of xxmaj victor xxmaj vargas is that he 's a sexually active teenager with a xxunk the size of xxmaj manhattan . xxmaj he 's a total xxmaj xxunk - male . xxmaj victor xxmaj vargas is not the kind of character i sympathize with at all . xxmaj why should anyone ? xxmaj so by the end of the movie , in the aftermath of the climax are we truly led to believe that somehow xxmaj victor xxmaj vargas has attained xxup any depth and learned the errors of his ways ? xxmaj how could such a two - dimensional character have any depth ? xxmaj if only the director had worried a little more about xxunk out his main character instead of worrying about getting that perfect hand - held shot . \\n\\n xxmaj raising xxmaj victor xxmaj vargas brings to life the world of the xxmaj latino inner - city neighborhood to the big screen . xxmaj something that few films have done before in the past . xxmaj the film has been xxunk for feeling so real , and i wo n't \\n\\n argue with that . i have n't seen this level of reality since xxup xxunk aired xxmaj survivor . xxmaj seriously , although the movie has some nice shots of the city , the writer / director xxmaj peter xxmaj sollett was way too xxunk on close - ups and hand - held shots . xxmaj this problem is particularly noticed in xxunk scenes that are so claustrophobic i was forced to perform deep - breathing xxunk to keep from passing out . xxmaj as the film continues , the shots get tighter and tighter with faces xxunk from xxunk to xxunk on the screen ; you can practically xxunk xxmaj victor xxmaj vargas 's cheap xxunk . xxmaj the overall effect is unrealistic in contrast . xxmaj the xxunk scenes of inner - city apartments make them look small and xxunk , which is not true . xxmaj i 've been in those type apartments ; i used to live in one . xxmaj they 're not xxunk but they have high xxunk and they 're decent living xxunk . xxmaj by the movie 's standards you 'd think that these apartments were xxunk xxunk of xxunk - and - xxunk , xxunk paint and xxunk walls . xxmaj unfortunately , xxmaj sollett 's constant use of close - ups and one particularly bad shot with a xxunk - in on one scene come off as totally amateurish . xxmaj but xxmaj raising xxmaj victor xxmaj vargas is only xxmaj sollett 's second film , and his most well known , a solid effort in filmmaking that will hopefully get better as he continues to make films . xxmaj one review i read xxunk the movie as , ` ethnicity for xxmaj ethnicity 's xxmaj sake , ' and i can not agree more . xxmaj if xxmaj victor xxmaj vargas were truly a great film and story , then the characters ' xxunk would n't matter whether they were xxmaj latino , xxmaj chinese , etc . xxmaj yet if you were to take this story and stick it in middle - class xxunk with a bunch of xxunk - xxunk white kids the results would n't be such glowing reviews , and we 'd see the film 's flaws more clearly . xxmaj indeed , some other aspects of the use of xxmaj latinos in this film bother me . xxmaj while some aspects of xxmaj victor xxmaj vargas are accurate others i have to question . xxmaj for example , xxmaj victor , xxmaj nino and xxmaj vicky all share the same room to sleep . xxmaj this set off an alarm for me because it seemed contrary to what i believe . xxmaj any self - xxunk xxmaj latino family would n't have two older brothers sharing the same room with a thirteen - year old girl . xxmaj at first i was xxunk , perhaps i was wrong , but after speaking with my grandmother i knew my problem with this was justified . xxmaj considering how conservative the grandmother is , you 'd think that xxmaj vicky would have been sleeping in her room . \\n\\n xxmaj as a xxmaj latino who grew up in a somewhat conservative xxmaj cuban household , raised by my grandmother while my mother was working full - time , i could relate to the movie in many ways , which is why my critical xxunk are xxunk because i really wanted to love this movie . xxmaj unfortunately , my lack of respect for xxmaj victor xxmaj vargas xxunk my feelings for the film . xxmaj maybe it 's because xxmaj victor xxmaj vargas reminds me of those guys who were getting laid while i was playing with my xxmaj xxunk xxmaj xxunk when i was xxunk . xxmaj maybe it 's because without any further xxunk by the film , xxmaj victor xxmaj vargas is merely a stereotypical hot - blooded xxmaj latino , who 'll just end up shouting to girls from his car , ` hey bay - xxunk , xxunk want to get into my xxunk xxunk - xxunk ? ' xxmaj either way i do n't like him , so ultimately how can i like a film about him ? xxmaj so if you 'll excuse me , xxmaj i 'm going to go stick my hands into a bowl of xxunk .</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>xxbos xxup the xxup shop xxup around xxup the xxup corner is one of the xxunk and most feel - good romantic comedies ever made . xxmaj there 's just no getting around that , and it 's hard to actually put one 's feeling for this film into words . xxmaj it 's not one of those films that tries too hard , nor does it come up with the xxunk possible scenarios to get the two protagonists together in the end . xxmaj in fact , all its charm is xxunk , contained within the characters and the setting and the plot … which is highly believable to xxunk . xxmaj it 's easy to think that such a love story , as beautiful as any other ever told , * could * happen to you … a feeling you do n't often get from other romantic comedies , however sweet and heart - warming they may be . \\n\\n xxmaj alfred xxmaj kralik ( james xxmaj stewart ) and xxmaj clara xxmaj xxunk ( margaret xxmaj xxunk ) do n't have the most xxunk of first xxunk when she arrives in the shop ( matuschek &amp; xxmaj co. ) he 's been working in for the past nine years , asking for a job . xxmaj they clash from the very beginning , mostly over a cigarette box that plays music when it 's opened -- he thinks it 's a ludicrous idea ; she makes one big sell of it and gets hired . xxmaj their bickering takes them through the next six months , even as they both ( xxunk , of course ! ) fall in love with each other when they share their souls and minds in letters passed through xxup xxunk xxmaj box xxunk . xxmaj this would be a pretty thin xxunk to base an entire film on , except that xxup the xxup shop xxup around xxup the xxup corner is xxunk xxunk - out with a brilliant supporting cast made up of entirely engaging characters , from the xxunk but lonely xxmaj hugo xxmaj matuschek ( frank xxmaj morgan ) himself , who learns that his shop really is his home ; xxmaj xxunk ( felix xxmaj xxunk ) , xxmaj kralik 's sidekick and friend who always xxunk out of the room when faced with the possibility of being asked for his honest opinion ; xxunk pimp - du - xxunk xxmaj xxunk ( joseph xxmaj xxunk ) who ultimately gets his comeuppance from a xxunk righteous xxmaj kralik ; and ambitious xxunk boy xxmaj xxunk xxmaj xxunk ( william xxmaj tracy ) who wants nothing more than to be promoted to the position of xxunk for xxmaj matuschek &amp; xxmaj co. xxmaj the xxunk love story between ' dear xxmaj friends ' is played out in this little shop in xxmaj budapest , xxmaj hungary , in which xxmaj kralik 's xxunk xxunk and subsequent xxunk to shop manager help the two xxunk - to - be along . xxmaj it 's nice that everyone gets a story in this film ; the supporting characters are well - developed , and xxmaj matuschek 's own journey in life is almost as touching as the one xxmaj alfred and xxmaj clara share . xxmaj his xxunk to new xxunk boy xxmaj xxunk ( charles xxmaj smith ) for xxmaj christmas xxmaj eve dinner , made in the xxunk , beautiful snow of a xxmaj hungarian winter , makes the audience glad that he is not alone ; we come to care even for the characters whose love story it is n't this film 's business to tell . \\n\\n xxmaj aside from the love story , i must say that xxmaj james xxmaj stewart is truly one of the best things about this film . xxmaj he does n't play the full - xxunk xxmaj jimmy xxmaj stewart persona in this film ( c / f ' mr xxmaj smith xxmaj goes xxmaj to xxmaj washington ' for that ) ; in fact xxmaj alfred xxmaj kralik is xxunk and abrupt and not particularly kind . xxmaj he 's rather a xxunk man , in fact , with little hint ( until , perhaps , the very end ) of the xxunk - xxunk down - home xxunk charm xxmaj stewart would soon come to xxunk . xxmaj when he finds out before xxmaj clara that they have been xxunk in secret , in fact , xxmaj kralik does n't ' xxunk up -- he xxunk it out to see how far he can take the xxunk , especially since he quickly realises ( given his stormy relationship with xxmaj clara as boss and xxunk ) that loving the person he knows through the xxunk letters might not xxunk with loving the person herself . xxmaj his description to xxmaj clara of the fictional xxmaj xxunk xxmaj xxunk ( what a name ! ) who was to become her xxunk is hilarious in the extreme , but also his way of proving that the letters do n't reveal all there is to a man , just as her letters do n't reveal all there is to her . xxmaj stewart plays this role perfectly -- he keeps his face perfectly controlled whenever xxmaj clara insults xxmaj mr . xxmaj kralik , as she is often wo nt to do , even ( and especially ) to his face . xxmaj and yet one believes , underneath the xxunk and xxunk , that he * could * reveal his identity with as much xxunk and xxunk and sheer * hope * as he eventually does . \\n\\n xxmaj special mention must be given to the other members of the cast as well . xxmaj margaret xxmaj xxunk xxunk rather less well in the first half of the film , but she really comes into her own in the closing - shop scene on xxmaj christmas xxmaj eve , when she almost gets her heart broken again by xxmaj alfred 's most vivid description of her xxunk xxunk . xxmaj frank xxmaj morgan turns in a great performance as the jealous xxmaj hugo xxmaj matuschek driven to nervous breakdown , the man who has to xxunk his meaning in life when he realises that his wife of 22 years does not want to ' grow old with him ' . xxmaj and xxmaj felix xxmaj xxunk plays the role of the meek but xxunk xxmaj xxunk wonderfully ( a xxmaj lubitsch regular , since he appears as a hilarious xxmaj russian xxunk in xxunk particular note is the scene in which he helps his good friend xxmaj alfred get the xxmaj christmas present the latter * really * wants … a wallet instead of that ludicrous cigarette box xxmaj clara is so hung up on . \\n\\n xxmaj xxunk xxmaj lubitsch really does himself proud with this film -- for example , the famously xxunk and xxunk care given to detail in the creation of the xxmaj matuschek shop is well worth the effort , right down to the xxmaj hungarian names on the door , the xxunk and the cash xxunk and so on . xxmaj but even though xxmaj lubitsch chose to have the story set in xxmaj hungary , the setting is actually universal : it could happen anywhere ; it could happen to you . xxmaj xxunk lies the charm of this simple story , these believable characters who really * are * people . xxmaj the snow on xxmaj christmas xxmaj eve is real as well , or at least as real as xxmaj lubitsch could make it ( he had snow machines brought in at great expense ) . xxmaj it is this desire to make everything appear as real as possible that helps make the story even more believable , that gives this entire film a dreamy realism that can not be xxunk . ( no , not even in a remake like xxup you 've xxup got xxup mail . ) \\n\\n * this * is really the xxmaj jimmy xxmaj stewart xxmaj christmas film that people are missing out on when they talk about xxup it 's a xxup wonderful xxup life . xxmaj not to xxunk from the merits of that other film , but there 'd be no harm , and in fact a lot of good , done in watching xxup the xxup shop xxup around xxup the xxup corner this xxmaj christmas instead . xxmaj it 's sweet , funny , charming , and xxmaj stewart is xxunk in his role . xxmaj we should all be so lucky as to have the romance depicted in this film ; the best thing about this film is that we come away from it feeling that we very possibly could .</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj xxunk , after xxunk ) , i can xxunk join both xxunk of \" at xxmaj the xxmaj movies \" in taking xxmaj steven xxmaj soderbergh to task . \\n\\n xxmaj it 's usually satisfying to watch a film director change his style / subject , but xxmaj soderbergh 's most recent stinker , xxmaj the xxmaj girlfriend xxmaj xxunk ) , was also missing a story , so narrative ( and editing ? ) seem to suddenly be xxmaj soderbergh 's main challenge . xxmaj strange , after xxunk years in the business . xxmaj he was probably never much good at narrative , just xxunk it well inside \" edgy \" projects . \\n\\n xxmaj none of this excuses him this present , almost diabolical failure . xxmaj as xxmaj david xxmaj stratton xxunk , \" two parts of xxmaj che do n't ( even ) make a whole \" . \\n\\n xxmaj epic xxunk in name only , xxmaj che(2008 ) barely qualifies as a feature film ! xxmaj it certainly has no legs , xxunk as except for its xxunk ultimate resolution forced upon it by history , xxmaj soderbergh 's xxunk - long xxunk just goes nowhere . \\n\\n xxmaj even xxmaj margaret xxmaj xxunk , the more xxunk of xxmaj australia 's xxmaj at xxmaj the xxmaj movies duo , noted about xxmaj soderbergh 's xxunk waste of ( xxunk digital xxunk ) : \" you 're in the woods … you 're in the woods … you 're in the woods … \" . i too am surprised xxmaj soderbergh did n't give us another xxunk of xxup that somewhere between his xxunk two xxmaj parts , because he still left out massive xxunk of xxmaj che 's \" xxunk \" life ! \\n\\n xxmaj for a xxunk of an important but infamous historical figure , xxmaj soderbergh xxunk xxunk , if not deliberately insults , his audiences by \\n\\n 1 . never providing most of xxmaj che 's story ; \\n\\n 2 . xxunk xxunk film xxunk with mere xxunk xxunk ; \\n\\n 3 . xxunk both true hindsight and a narrative of events ; \\n\\n 4 . barely developing an idea , or a character ; \\n\\n 5 . remaining xxunk episodic ; \\n\\n 6 . xxunk proper context for scenes xxrep 3 - whatever we do get is xxunk in xxunk xxunk ; \\n\\n 7 . xxunk xxunk all audiences ( even xxmaj spanish - xxunk will be confused by the xxunk xxunk in xxmaj english ) ; and \\n\\n 8 . xxunk xxunk his main subject into one dimension . xxmaj why , at xxup this late stage ? xxmaj the xxmaj t - shirt franchise has been a success ! \\n\\n xxmaj our sense of xxunk is surely due to xxmaj peter xxmaj xxunk and xxmaj benjamin xxunk xxmaj xxunk xxunk their screenplay solely on xxmaj xxunk 's memoirs . xxmaj so , like a poor student who has read only xxup one of his xxunk xxunk for his xxunk , xxmaj soderbergh 's product is xxunk limited in perspective . \\n\\n xxmaj the audience is held captive within the same xxunk knowledge , scenery and circumstances of the \" revolutionaries \" , but that does n't xxunk our sympathy . xxmaj instead , it xxunk on us that \" ah , xxmaj soderbergh 's trying to xxunk his audiences the same as the xxmaj latino peasants were at the time \" . xxmaj but these are the xxup same illiterate xxmaj latino peasants who sold out the good doctor to his enemies . xxmaj why does xxmaj soderbergh feel the need to xxunk us with them , and keep us equally mentally captive ? xxmaj such audience xxunk must have a purpose . \\n\\n xxmaj part2 is more xxunk than xxmaj part1 , but it 's literally mind - numbing with its repetitive bush - bashing , misery of outlook , and lack of variety or character xxunk . deltoro 's xxmaj che has no opportunity to grow as a person while he struggles to xxunk his own ill - xxunk troops . xxmaj the only xxunk is the humour as xxmaj che deals with his sometimes deeply ignorant \" revolutionaries \" , some of whom xxunk lack self - control around local peasants or food . xxmaj we certainly get no insight into what caused the conditions , nor any xxunk xxunk of their xxunk xxunk , such as it was . \\n\\n xxmaj part2 's excruciating xxunk remains xxunk episodic : again , nothing is telegraphed or xxunk . xxmaj thus even the scenes with xxmaj xxunk xxmaj xxunk ( xxunk xxmaj xxunk ) are unexpected and disconcerting . xxmaj any xxunk events are portrayed xxunk and xxmaj latino - xxunk , with xxmaj part1 's interviews replaced by time - xxunk xxunk between the corrupt xxmaj xxunk president ( xxunk de xxmaj xxunk ) and xxup us xxmaj government xxunk promising xxup cia xxunk ( ! ) . \\n\\n xxmaj the rest of xxmaj part2 's \" woods \" and day - for - night blue xxunk just xxunk the audience until they 're xxunk the xxunk . \\n\\n xxmaj perhaps deltoro felt too xxunk the frustration of many non - american xxmaj latinos about never getting a truthful , xxunk history of xxmaj che 's exploits within their own countries . xxmaj when foreign xxunk still wo n't deliver a free press to their people -- for whatever reason -- then one can see how a popular xxmaj american indie producer might set out to entice the not - so - well - read ( \" i may not be able to read or write , but xxmaj i 'm xxup not xxunk xxmaj inspector xxmaj xxunk ) ) out to their own local cinemas . xxmaj the film 's obvious xxunk and gross over - xxunk hint very strongly that it 's aiming only at the xxunk of the less - informed xxup who xxup still xxup speak xxup little xxmaj english . xxmaj if they did , they 'd have read xxunk on the subject already , and xxunk the relevant social issues amongst themselves -- learning the lessons of history as they should . \\n\\n xxmaj such insights are precisely what societies still need -- and not just the remaining illiterate xxmaj latinos of xxmaj central and xxmaj south xxmaj america -- yet it 's what xxmaj che(2008 ) xxunk fails to deliver . xxmaj soderbergh xxunk his lead because he 's weak on narrative . i am xxunk why xxmaj xxunk deltoro deliberately chose xxmaj soderbergh for this project if he knew this . xxmaj it 's been xxunk , hindsight about xxmaj xxunk was xxunk wanted : it 's what i went to see this film for , but the director xxunk robs us of that . \\n\\n xxmaj david xxmaj stratton , writing in xxmaj the xxmaj australian ( xxunk ) observed that while xxmaj part1 was \" uneven \" , xxmaj part2 actually \" goes rapidly downhill \" from there , \" xxunk xxmaj che 's final campaign in xxmaj xxunk in excruciating detail \" , which \" … feels almost unbearably slow and turgid \" . \\n\\n che : the xxmaj xxunk aka xxmaj part2 is certainly no xxunk for xxmaj xxunk , painting it a picture of misery and xxunk . xxmaj the entire second half is only redeemed by the aforementioned humour , and the dramatic -- yet tragic -- capture and execution of the film 's subject . \\n\\n xxmaj the rest of this xxunk cinema xxunk is just confusing , irritating misery -- xxunk , for a xxmaj soderbergh film , to be avoided at all costs . xxmaj it is bound to break the hearts of all who know even just a xxunk about the xxunk / 10 )</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>xxbos xxmaj this film sat on my xxmaj xxunk for weeks before i watched it . i xxunk a self - indulgent xxunk flick about relationships gone bad . i was wrong ; this was an xxunk xxunk into the screwed - up xxunk of xxmaj new xxmaj xxunk . \\n\\n xxmaj the format is the same as xxmaj max xxmaj xxunk ' \" la xxmaj xxunk , \" based on a play by xxmaj arthur xxmaj xxunk , who is given an \" inspired by \" credit . xxmaj it starts from one person , a prostitute , standing on a street corner in xxmaj brooklyn . xxmaj she is picked up by a home contractor , who has sex with her on the hood of a car , but ca n't come . xxmaj he refuses to pay her . xxmaj when he 's off xxunk , she answers his cell phone and takes a message . xxmaj she runs away with his keys . \\n\\n xxmaj then the story switches to the contractor , who pays a professional call on a rich , bored xxmaj new xxmaj york woman , who plays with him until he is xxunk , then she pulls away . xxmaj she tells him how desperate and unhappy she is ; he tells her how beautiful she is , and lucky . xxmaj as he is leaving , she asks if he would have sex with her . xxmaj she sits on top of him , xxunk up and down . xxmaj this time he comes , the he leaves . \\n\\n xxmaj the woman and her husband throw a dinner party for their xxunk friends . xxmaj xxunk ( robert ) is talking business , wife ( ellen ) is bored , and switches the subject to sex , and how often men and women think about it . xxmaj husband switches conversation to desert . xxmaj later , after the xxunk leave , xxmaj ellen tries to entice xxmaj robert into sex . xxmaj robert wants none of it , and puts on a jazz record . xxmaj ellen turns on the radio ; xxmaj robert turns up the music ; xxmaj ellen turns on the xxup tv ; xxmaj robert turns on another xxup tv . xxmaj xxunk ensues . xxmaj ellen goes up on the roof , xxmaj robert joins her . xxmaj ellen confesses that she needs to experience more men , men other than xxmaj robert . xxmaj robert says that he too needs to experience men . \\n\\n xxmaj we next follow xxmaj robert as he visits an artist , xxmaj martin , played by xxmaj steve xxmaj buscemi . i wish xxmaj buscemi could have more roles like this , where he is a sexy , smart , totally xxunk guy . xxmaj robert xxunk xxmaj martin 's work , much more than it deserves , xxunk to get it into a show . xxmaj martin is excited , until it turns out that xxmaj robert is speaking out of his xxunk , it is all a xxunk dance . xxmaj robert tries to kiss xxmaj martin , on the lips , and xxmaj martin pulls back , saying that he is not gay . xxmaj robert xxunk that he 's not gay either , xxmaj martin xxunk . xxmaj both admit that the xxunk are bad . xxmaj robert is about to leave , when xxmaj martin allows xxmaj robert to kiss him . xxmaj they make out , and xxmaj robert goes down on xxmaj martin . \\n\\n xxmaj next we follow xxmaj martin , as he xxunk for an art show at a xxmaj manhattan gallery . xxmaj he is xxunk by the xxunk , xxmaj anna , played by xxmaj rosario xxmaj dawson . ( i had to cut some of this review to keep it under 1 xxrep 3 0 words ) … and they make love to each other . \\n\\n xxmaj we next follow xxmaj anna , who is sitting at a lunch stand . xxmaj her boyfriend , xxmaj nick ( adrian xxmaj xxunk ) , enters , bearing xxunk . xxmaj she is cold toward him ; he tries to figure out why . xxmaj he coaxes out of her the information that she has had sex with someone while he was in xxmaj san xxmaj francisco . xxmaj she coaxes out of him the fact that he has stayed with his ex - xxunk while in xxmaj san xxmaj francisco , and had sex with her . xxmaj the latter revelation turns out to be a lie . xxmaj the two of them make out in the xxunk , but she decides that they must break up . xxmaj nick is xxunk . \\n\\n xxmaj and we follow xxmaj nick , who confesses his xxunk to an older woman who he meets on a park bench , xxmaj joey ( carol xxmaj kane ) . xxmaj joey is sort of weird and child - like , but is a good audience for xxmaj nick , who needs a sympathetic ear . xxmaj the two of them go to xxmaj xxunk xxmaj island at night , and look at the stars . xxmaj nick falls under xxmaj joey 's spell , despite the age difference between them . xxmaj they go back to xxmaj joey 's apartment , and xxmaj nick gradually realizes that he is about to have sex with a crazy old woman . xxmaj she is on top of him , does n't want to let him go . xxmaj but he manages to escape . \\n\\n ( this is , by the way , the best xxmaj carol xxmaj kane role since she played xxmaj xxunk 's wife in xxmaj taxi . ) xxmaj joey 's phone rings , and it is a man calling the xxmaj psychic xxmaj friends xxmaj network , and xxmaj joey is one of the psychic friends . xxmaj although she is still hurting from xxmaj nick , she gradually gets into her psychic xxunk . xxmaj the man is at his office , late at night , and wants to have phone sex with her . xxmaj although that is not xxmaj joey 's business , xxmaj joey goes along , and coaxes the man to come . xxmaj she wants to keep talking , although the man want to get off the phone , and finds out that he has xxunk a lot of money from his company , and will be found out xxunk . xxmaj his life is ruined . xxmaj joey realizes that the man is going to commit suicide , and she tries to make him believe that she is his friend , that she cares about him . xxmaj and she does care about him . \\n\\n xxmaj but the man packs a gun into his xxunk , and goes off to seek a prostitute on the xxmaj brooklyn xxunk , and we come back to the beginning , to the same prostitute who started out xxmaj la xxmaj xxunk . xxmaj she wants to give him $ xxunk , xxrep 3 0 in cash if she will kill him . xxmaj he tried to kill himself , but could n't do it . xxmaj the prostitute does not want to do it , but he insists , holding her hand , holding the gun inside his mouth , telling her where to aim . xxmaj eventually , the gun goes off , and we see the prostitute walking down the street , and xxunk at the corner where she normally does business . xxmaj the contractor who did n't pay her earlier in the movie drives up , xxunk down the window . xxmaj they look at each other . xxup the xxup end .</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uy8YoQJ9u878",
        "colab_type": "text"
      },
      "source": [
        "Now let's train!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z07pMFgu-zk",
        "colab_type": "text"
      },
      "source": [
        "## Training the Classifier\n",
        "\n",
        "Let's use our `text_classifier_learner` again, and pass in our databunch, the architecture, vocab, our metrics, our dropout multiplier, and our optimizer. We also need to pass in our **original** path to grab our encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuDhdCxZuiBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = text_classifier_learner(dbunch, AWD_LSTM, vocab, metrics=[accuracy],\n",
        "                                drop_mult=0.5, opt_func=opt_func, path=path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZsfzgv_vb1s",
        "colab_type": "text"
      },
      "source": [
        "We can then load in our encoder from earlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_vywIezva_r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = learn.load_encoder('finetuned');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHudOawqv2XT",
        "colab_type": "text"
      },
      "source": [
        "And lastly convert it over to Mixed Precision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1VL_hbJve8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = learn.to_fp16(clip=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_diP_eTv8XT",
        "colab_type": "text"
      },
      "source": [
        "And now we can gradually unfreeze for differential learning rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyadba40v7fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-1 * 64/128\n",
        "moms = (0.8,0.7,0.8)\n",
        "wd = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5JF6aGOwB2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "744e8d5b-71cf-4912-b613-04c7f16d8d98"
      },
      "source": [
        "learn.fit_one_cycle(1, lr_max=lr, moms=moms, wd=wd)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.878782</td>\n",
              "      <td>0.870123</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>00:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRR1mKhhwMF6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "3fe6dfcd-fbdf-424b-b783-adc61c3bf698"
      },
      "source": [
        "learn.freeze_to(-2)\n",
        "lr /= 2\n",
        "learn.fit_one_cycle(1, slice(lr/(2.6**4),lr), moms=moms, wd=wd)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.620861</td>\n",
              "      <td>0.736504</td>\n",
              "      <td>0.715000</td>\n",
              "      <td>00:17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3ndMXuK2d2K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "outputId": "0f218863-23de-4b64-a14f-339062fb2346"
      },
      "source": [
        "learn.freeze_to(-3)\n",
        "lr /= 2\n",
        "learn.fit_one_cycle(1, slice(lr/(2.6**4),lr), moms=moms, wd=wd)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.475432</td>\n",
              "      <td>0.383862</td>\n",
              "      <td>0.815000</td>\n",
              "      <td>00:30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7uH-TbB2kEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "4ccbef85-fd3a-4b96-efc8-2f202c0cc512"
      },
      "source": [
        "learn.unfreeze()\n",
        "lr /= 5\n",
        "learn.fit_one_cycle(2, slice(lr/(2.6**4), lr), moms=moms, wd=wd)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.386622</td>\n",
              "      <td>0.374377</td>\n",
              "      <td>0.835000</td>\n",
              "      <td>00:35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.341903</td>\n",
              "      <td>0.388184</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>00:33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz-PLiZ-2_7N",
        "colab_type": "text"
      },
      "source": [
        "This model is not the most accurate when compared to regular `IMDB` as it is a subsample. In `09b` I will show that process through and explain how the API may be different there. Thanks for reading!"
      ]
    }
  ]
}